# CSV Data Agent

Sistema de an√°lisis de datos conversacional que permite hacer preguntas en lenguaje natural sobre archivos CSV y obtener respuestas mediante generaci√≥n y ejecuci√≥n autom√°tica de c√≥digo Pandas.

---

## Objetivo

Construir un agente que:

1. Cargue cualquier archivo CSV
2. Entienda su estructura (columnas, tipos, datos)
3. Reciba preguntas en lenguaje natural del usuario
4. Genere c√≥digo Pandas para responder la pregunta
5. Ejecute el c√≥digo de forma segura
6. Devuelva el resultado (n√∫mero, tabla, gr√°fico)
7. Mantenga contexto conversacional para an√°lisis iterativo

**Caso de uso principal:** An√°lisis de datos de sistemas antidron (timestamps, se√±ales RF, detecciones) sin necesidad de escribir c√≥digo manualmente.

---

## Stack tecnol√≥gico

| Componente | Tecnolog√≠a | Justificaci√≥n |
|------------|------------|---------------|
| Lenguaje | Python 3.10+ | Ecosistema de datos maduro |
| Datos | Pandas | Est√°ndar para manipulaci√≥n tabular |
| LLM | Groq API (Llama 3.1 70B) | Gratis, r√°pido, buena generaci√≥n de c√≥digo |
| Interfaz | Streamlit | Prototipado r√°pido, visual, sin frontend |
| Gr√°ficos | Matplotlib/Plotly | Integraci√≥n nativa con Streamlit |
| Entorno | venv | Sin dependencias externas complejas |

---

## Arquitectura

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                        STREAMLIT UI                         ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ Upload CSV  ‚îÇ  ‚îÇ Chat Input  ‚îÇ  ‚îÇ Results Display     ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                              ‚îÇ
                              ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                      CORE ENGINE                            ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ CSV Loader  ‚îÇ  ‚îÇ Schema      ‚îÇ  ‚îÇ Conversation        ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ             ‚îÇ‚îÄ‚îÄ‚ñ∂ Analyzer    ‚îÇ‚îÄ‚îÄ‚ñ∂ Manager             ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                              ‚îÇ
                              ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                      LLM LAYER                              ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ Prompt      ‚îÇ  ‚îÇ Claude API  ‚îÇ  ‚îÇ Response Parser     ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ Builder     ‚îÇ‚îÄ‚îÄ‚ñ∂ Client      ‚îÇ‚îÄ‚îÄ‚ñ∂                     ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                              ‚îÇ
                              ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    EXECUTION LAYER                          ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ Code        ‚îÇ  ‚îÇ Safe        ‚îÇ  ‚îÇ Result Formatter    ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ Extractor   ‚îÇ‚îÄ‚îÄ‚ñ∂ Executor    ‚îÇ‚îÄ‚îÄ‚ñ∂                     ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## Estructura de archivos

```
csv-agent/
‚îú‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ requirements.txt
‚îú‚îÄ‚îÄ .env.example
‚îú‚îÄ‚îÄ .gitignore
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ csv_loader.py        # Carga y validaci√≥n de CSV
‚îÇ   ‚îú‚îÄ‚îÄ schema_analyzer.py   # An√°lisis de estructura del DataFrame
‚îÇ   ‚îú‚îÄ‚îÄ prompt_builder.py    # Construcci√≥n de prompts para el LLM
‚îÇ   ‚îú‚îÄ‚îÄ llm_client.py        # Cliente de Claude API
‚îÇ   ‚îú‚îÄ‚îÄ code_executor.py     # Ejecuci√≥n segura de c√≥digo
‚îÇ   ‚îú‚îÄ‚îÄ result_formatter.py  # Formateo de resultados
‚îÇ   ‚îî‚îÄ‚îÄ conversation.py      # Gesti√≥n del historial
‚îú‚îÄ‚îÄ app.py                   # Aplicaci√≥n Streamlit
‚îú‚îÄ‚îÄ tests/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ test_csv_loader.py
‚îÇ   ‚îú‚îÄ‚îÄ test_schema_analyzer.py
‚îÇ   ‚îú‚îÄ‚îÄ test_code_executor.py
‚îÇ   ‚îî‚îÄ‚îÄ sample_data/
‚îÇ       ‚îî‚îÄ‚îÄ test_antidron.csv
‚îî‚îÄ‚îÄ docs/
    ‚îî‚îÄ‚îÄ prompts.md           # Documentaci√≥n de prompts usados
```

---

## Fases del proyecto

### Fase 1: Setup y estructura base
Preparar el entorno de desarrollo y la estructura del proyecto.

### Fase 2: Carga y an√°lisis de CSV
Implementar la carga de archivos y extracci√≥n de metadatos.

### Fase 3: Integraci√≥n con LLM
Conectar con Claude API y dise√±ar los prompts.

### Fase 4: Ejecuci√≥n de c√≥digo
Implementar la ejecuci√≥n segura del c√≥digo generado.

### Fase 5: Interfaz de usuario
Crear la aplicaci√≥n Streamlit.

### Fase 6: Mejoras y robustez
A√±adir funcionalidades avanzadas y pulir el sistema.

---

## Tareas detalladas

### Fase 1: Setup y estructura base

#### Tarea 1.1: Crear estructura de directorios
```bash
mkdir -p csv-agent/{src,tests/sample_data,docs}
touch csv-agent/src/__init__.py
touch csv-agent/tests/__init__.py
```
**Criterio de completitud:** Estructura de carpetas creada.

#### Tarea 1.2: Crear entorno virtual
```bash
cd csv-agent
python -m venv venv
source venv/bin/activate  # Linux/Mac
```
**Criterio de completitud:** Entorno activado, `which python` apunta al venv.

#### Tarea 1.3: Crear requirements.txt
```
pandas==2.1.4
groq==0.5.0
streamlit==1.31.0
python-dotenv==1.0.0
matplotlib==3.8.2
plotly==5.18.0
```
**Criterio de completitud:** `pip install -r requirements.txt` ejecuta sin errores.

#### Tarea 1.4: Crear .env.example
```
GROQ_API_KEY=tu_api_key_aqui
```
**Criterio de completitud:** Archivo creado con placeholder.

#### Tarea 1.5: Crear .gitignore
```
venv/
__pycache__/
.env
*.pyc
.DS_Store
```
**Criterio de completitud:** Archivo creado.

#### Tarea 1.6: Crear CSV de prueba
Crear `tests/sample_data/test_antidron.csv` con datos simulados:
```csv
timestamp,frequency_mhz,rssi_dbm,protocol,drone_id,latitude,longitude
2024-01-15 10:30:00,2437.5,-65,WiFi,DJI_001,40.4168,-3.7038
2024-01-15 10:30:05,2437.5,-68,WiFi,DJI_001,40.4169,-3.7039
...
```
Incluir al menos 100 filas con variaci√≥n en todos los campos.
**Criterio de completitud:** CSV creado con datos realistas y variados.

---

### Fase 2: Carga y an√°lisis de CSV

#### Tarea 2.1: Implementar csv_loader.py

**Archivo:** `src/csv_loader.py`

**Funcionalidad:**
- Funci√≥n `load_csv(file_path: str | BytesIO) -> pd.DataFrame`
- Detectar encoding autom√°ticamente (utf-8, latin-1, cp1252)
- Detectar separador autom√°ticamente (coma, punto y coma, tab)
- Parsear columnas de fecha autom√°ticamente
- Manejar errores de carga con mensajes claros

**Interfaz:**
```python
def load_csv(file) -> pd.DataFrame:
    """
    Carga un CSV desde path o BytesIO.
    
    Args:
        file: Path al archivo o BytesIO desde upload
        
    Returns:
        DataFrame con datos cargados
        
    Raises:
        ValueError: Si el archivo no es v√°lido
    """
    pass
```

**Criterio de completitud:** 
- Carga correctamente el CSV de prueba
- Detecta autom√°ticamente el formato de fecha
- Test unitario pasa

#### Tarea 2.2: Implementar schema_analyzer.py

**Archivo:** `src/schema_analyzer.py`

**Funcionalidad:**
- Funci√≥n `analyze_schema(df: pd.DataFrame) -> dict`
- Extraer: nombre columnas, tipos, valores √∫nicos (si < 20), min/max, nulls
- Funci√≥n `get_sample_rows(df: pd.DataFrame, n: int = 5) -> str`
- Funci√≥n `generate_schema_description(df: pd.DataFrame) -> str` que genera texto legible

**Interfaz:**
```python
def analyze_schema(df: pd.DataFrame) -> dict:
    """
    Analiza la estructura del DataFrame.
    
    Returns:
        {
            "columns": [
                {
                    "name": "timestamp",
                    "dtype": "datetime64[ns]",
                    "null_count": 0,
                    "unique_count": 1000,
                    "sample_values": ["2024-01-15 10:30:00", ...],
                    "min": "2024-01-15 10:30:00",
                    "max": "2024-01-16 18:45:00"
                },
                ...
            ],
            "row_count": 1000,
            "memory_usage_mb": 0.5
        }
    """
    pass

def generate_schema_description(df: pd.DataFrame) -> str:
    """
    Genera descripci√≥n en texto del esquema para el LLM.
    
    Returns:
        String formateado describiendo el DataFrame
    """
    pass
```

**Criterio de completitud:**
- Genera esquema correcto del CSV de prueba
- La descripci√≥n es clara y concisa
- Test unitario pasa

---

### Fase 3: Integraci√≥n con LLM

#### Tarea 3.1: Implementar llm_client.py

**Archivo:** `src/llm_client.py`

**Funcionalidad:**
- Clase `LLMClient` que encapsula la API de Groq
- M√©todo `query(prompt: str, system: str = None) -> str`
- Modelo: `llama-3.1-70b-versatile`
- Manejo de rate limits con retry exponencial
- Logging de tokens usados

**Interfaz:**
```python
class LLMClient:
    def __init__(self, api_key: str = None, model: str = "llama-3.1-70b-versatile"):
        """Inicializa cliente. Si no hay key, lee de .env"""
        pass
    
    def query(self, prompt: str, system: str = None) -> str:
        """
        Env√≠a query a Groq y devuelve respuesta.
        
        Args:
            prompt: Mensaje del usuario
            system: System prompt opcional
            
        Returns:
            Respuesta del modelo como string
        """
        pass
```

**Criterio de completitud:**
- Conecta con API de Groq correctamente
- Maneja errores de API gracefully
- Test manual con query simple funciona

#### Tarea 3.2: Implementar prompt_builder.py

**Archivo:** `src/prompt_builder.py`

**Funcionalidad:**
- Funci√≥n `build_system_prompt(schema_description: str) -> str`
- Funci√≥n `build_user_prompt(question: str, conversation_history: list = None) -> str`
- El system prompt debe instruir al LLM a:
  - Generar SOLO c√≥digo Pandas v√°lido
  - Usar la variable `df` que ya existe
  - Guardar resultado en variable `result`
  - No usar print(), solo asignar a `result`
  - Manejar fechas con pd.to_datetime si es necesario

**System prompt base:**
```python
SYSTEM_PROMPT_TEMPLATE = """
Eres un analista de datos experto. Tu tarea es generar c√≥digo Pandas para responder preguntas sobre un DataFrame.

REGLAS ESTRICTAS:
1. Genera √öNICAMENTE c√≥digo Python v√°lido
2. El DataFrame ya existe en la variable `df`
3. Guarda el resultado final en la variable `result`
4. NO uses print(), solo asigna a `result`
5. Para fechas, la columna timestamp ya es datetime
6. Si necesitas mostrar un gr√°fico, usa matplotlib y guarda la figura en `result_fig`
7. Responde SOLO con c√≥digo, sin explicaciones

ESQUEMA DEL DATAFRAME:
{schema_description}

EJEMPLOS DE C√ìDIGO V√ÅLIDO:

Pregunta: ¬øCu√°ntas filas tiene el dataset?
C√≥digo:
result = len(df)

Pregunta: ¬øCu√°l es la media de rssi_dbm?
C√≥digo:
result = df['rssi_dbm'].mean()

Pregunta: ¬øCu√°ntas detecciones hubo entre 10:00 y 12:00 del 15 de enero?
C√≥digo:
mask = (df['timestamp'] >= '2024-01-15 10:00:00') & (df['timestamp'] <= '2024-01-15 12:00:00')
result = df[mask].shape[0]
"""
```

**Interfaz:**
```python
def build_system_prompt(schema_description: str) -> str:
    """Construye system prompt con el esquema del DataFrame."""
    pass

def build_user_prompt(question: str, conversation_history: list = None) -> str:
    """Construye prompt del usuario, opcionalmente con historial."""
    pass
```

**Criterio de completitud:**
- System prompt incluye esquema correctamente
- Prompts generados son claros y concisos
- Test con preguntas de ejemplo genera c√≥digo v√°lido

#### Tarea 3.3: Crear docs/prompts.md
Documentar todos los prompts usados, su prop√≥sito, y ejemplos de entrada/salida.

**Criterio de completitud:** Documento completo y claro.

---

### Fase 4: Ejecuci√≥n de c√≥digo

#### Tarea 4.1: Implementar code_executor.py

**Archivo:** `src/code_executor.py`

**Funcionalidad:**
- Funci√≥n `extract_code(llm_response: str) -> str` que extrae c√≥digo de la respuesta
- Funci√≥n `execute_code(code: str, df: pd.DataFrame) -> ExecutionResult`
- Ejecuci√≥n en namespace aislado
- Timeout de ejecuci√≥n (m√°ximo 30 segundos)
- Captura de errores con traceback limpio

**Interfaz:**
```python
@dataclass
class ExecutionResult:
    success: bool
    result: any  # El valor de `result` despu√©s de ejecutar
    result_fig: any  # Figura matplotlib si existe
    error: str = None  # Mensaje de error si fall√≥
    execution_time: float = 0.0

def extract_code(llm_response: str) -> str:
    """
    Extrae c√≥digo Python de la respuesta del LLM.
    Maneja respuestas con o sin bloques ```python```.
    """
    pass

def execute_code(code: str, df: pd.DataFrame, timeout: int = 30) -> ExecutionResult:
    """
    Ejecuta c√≥digo Pandas de forma segura.
    
    Args:
        code: C√≥digo Python a ejecutar
        df: DataFrame sobre el que operar
        timeout: Segundos m√°ximos de ejecuci√≥n
        
    Returns:
        ExecutionResult con el resultado o error
    """
    pass
```

**Consideraciones de seguridad:**
- NO permitir imports arbitrarios (solo pandas, numpy, matplotlib)
- NO permitir acceso a filesystem (open, os, sys)
- NO permitir ejecuci√≥n de comandos (subprocess, os.system)
- Implementar lista blanca de funciones permitidas

**Criterio de completitud:**
- Ejecuta c√≥digo v√°lido correctamente
- Captura errores sin crashear
- Bloquea c√≥digo malicioso
- Test unitario con casos v√°lidos e inv√°lidos pasa

#### Tarea 4.2: Implementar result_formatter.py

**Archivo:** `src/result_formatter.py`

**Funcionalidad:**
- Funci√≥n `format_result(result: ExecutionResult) -> dict`
- Detectar tipo de resultado (n√∫mero, string, DataFrame, figura)
- Formatear para display apropiado
- Truncar DataFrames grandes (max 100 filas en display)

**Interfaz:**
```python
def format_result(execution_result: ExecutionResult) -> dict:
    """
    Formatea resultado para mostrar en UI.
    
    Returns:
        {
            "type": "number" | "string" | "dataframe" | "figure" | "error",
            "value": <valor formateado>,
            "raw": <valor original>,
            "display_html": <HTML para renderizar si aplica>
        }
    """
    pass
```

**Criterio de completitud:**
- Formatea correctamente todos los tipos de resultado
- DataFrames grandes se truncan con mensaje indicando total
- Test unitario pasa

---

### Fase 5: Interfaz de usuario

#### Tarea 5.1: Implementar conversation.py

**Archivo:** `src/conversation.py`

**Funcionalidad:**
- Clase `ConversationManager` que mantiene historial
- Almacenar pares (pregunta, c√≥digo, resultado)
- M√©todo para generar contexto para el LLM
- M√©todo para limpiar conversaci√≥n

**Interfaz:**
```python
@dataclass
class ConversationTurn:
    question: str
    code: str
    result_summary: str
    timestamp: datetime

class ConversationManager:
    def __init__(self, max_history: int = 10):
        """Inicializa con historial m√°ximo."""
        pass
    
    def add_turn(self, question: str, code: str, result_summary: str):
        """A√±ade un turno a la conversaci√≥n."""
        pass
    
    def get_context_for_llm(self) -> str:
        """Genera resumen del historial para incluir en prompt."""
        pass
    
    def clear(self):
        """Limpia el historial."""
        pass
```

**Criterio de completitud:**
- Mantiene historial correctamente
- Genera contexto √∫til para el LLM
- Limita historial al m√°ximo configurado

#### Tarea 5.2: Implementar app.py (estructura base)

**Archivo:** `app.py`

**Funcionalidad inicial:**
- Layout de Streamlit con sidebar y √°rea principal
- Sidebar: upload de CSV, bot√≥n de limpiar
- √Årea principal: zona de chat
- Estado de sesi√≥n para df, conversaci√≥n, resultados

**Estructura:**
```python
import streamlit as st

st.set_page_config(
    page_title="CSV Data Agent",
    page_icon="üìä",
    layout="wide"
)

# Inicializar estado de sesi√≥n
if "df" not in st.session_state:
    st.session_state.df = None
if "conversation" not in st.session_state:
    st.session_state.conversation = ConversationManager()
if "messages" not in st.session_state:
    st.session_state.messages = []

# Sidebar
with st.sidebar:
    st.header("üìÅ Cargar datos")
    uploaded_file = st.file_uploader("Sube un CSV", type="csv")
    # ... resto de sidebar

# √Årea principal
st.title("üìä CSV Data Agent")

if st.session_state.df is None:
    st.info("üëà Sube un CSV para empezar")
else:
    # Mostrar chat
    # ...
```

**Criterio de completitud:**
- App arranca sin errores
- Se puede subir CSV
- Layout es claro y funcional

#### Tarea 5.3: Implementar flujo completo en app.py

**Funcionalidad:**
- Al subir CSV: cargar, analizar, mostrar preview
- Input de chat para preguntas
- Al enviar pregunta:
  1. Mostrar pregunta en chat
  2. Construir prompt con esquema y contexto
  3. Llamar a LLM
  4. Extraer y ejecutar c√≥digo
  5. Mostrar resultado
  6. Guardar en historial
- Mostrar c√≥digo generado (colapsable)
- Mostrar errores de forma clara

**Criterio de completitud:**
- Flujo completo funciona end-to-end
- Se pueden hacer m√∫ltiples preguntas seguidas
- Errores se muestran sin crashear la app

#### Tarea 5.4: A√±adir visualizaci√≥n de esquema

**Funcionalidad:**
- En sidebar, mostrar resumen del CSV cargado:
  - N√∫mero de filas y columnas
  - Lista de columnas con tipos
  - Preview de primeras 5 filas
- Colapsable para no ocupar mucho espacio

**Criterio de completitud:**
- Informaci√≥n de esquema visible y clara
- No interfiere con el flujo principal

---

### Fase 6: Mejoras y robustez

#### Tarea 6.1: A√±adir manejo de errores mejorado

**Funcionalidad:**
- Si el c√≥digo falla, pedir al LLM que lo corrija
- M√°ximo 2 reintentos autom√°ticos
- Mostrar al usuario qu√© se intent√≥

**Criterio de completitud:**
- Errores simples se auto-corrigen
- Usuario ve el proceso de correcci√≥n

#### Tarea 6.2: A√±adir generaci√≥n de gr√°ficos

**Funcionalidad:**
- Detectar cuando la pregunta pide visualizaci√≥n
- Instrucciones en prompt para generar gr√°ficos
- Renderizar figura en Streamlit

**Ejemplo de pregunta:** "Mu√©strame un gr√°fico de la se√±al rssi a lo largo del tiempo"

**Criterio de completitud:**
- Gr√°ficos se generan y muestran correctamente
- Al menos soporta: l√≠neas, barras, histogramas

#### Tarea 6.3: A√±adir sugerencias de an√°lisis

**Funcionalidad:**
- Al cargar CSV, generar 3-5 preguntas sugeridas
- Basadas en el esquema detectado
- Clickeables para ejecutar directamente

**Criterio de completitud:**
- Sugerencias son relevantes al dataset
- Click ejecuta la pregunta

#### Tarea 6.4: A√±adir export de resultados

**Funcionalidad:**
- Bot√≥n para exportar resultado actual como CSV
- Bot√≥n para exportar historial de conversaci√≥n

**Criterio de completitud:**
- Exports funcionan correctamente
- Archivos son v√°lidos

#### Tarea 6.5: Testing final

**Funcionalidad:**
- Probar con al menos 3 CSVs diferentes
- Documentar casos que funcionan y casos l√≠mite
- Escribir tests unitarios para componentes cr√≠ticos

**Criterio de completitud:**
- Cobertura de tests > 70% en m√≥dulos core
- Documentaci√≥n de limitaciones conocidas

---

## Gu√≠a de uso

### Instalaci√≥n

```bash
# Clonar o crear directorio
cd csv-agent

# Crear entorno virtual
python -m venv venv
source venv/bin/activate

# Instalar dependencias
pip install -r requirements.txt

# Configurar API key
cp .env.example .env
# Editar .env y a√±adir tu GROQ_API_KEY (conseguir en https://console.groq.com)
```

### Ejecuci√≥n

```bash
streamlit run app.py
```

Abre http://localhost:8501 en el navegador.

### Ejemplo de uso

1. Sube tu archivo CSV
2. Revisa el esquema detectado en el sidebar
3. Haz preguntas en lenguaje natural:
   - "¬øCu√°ntas detecciones hay en total?"
   - "¬øCu√°l es la media de rssi entre las 10:00 y las 12:00?"
   - "¬øQu√© protocolos aparecen y cu√°ntas veces cada uno?"
   - "Mu√©strame un gr√°fico de detecciones por hora"

---

## Limitaciones conocidas

- **Tama√±o de CSV:** Datasets muy grandes (>1M filas) pueden ser lentos
- **Complejidad de queries:** Preguntas muy complejas pueden generar c√≥digo incorrecto
- **Tipos de datos:** Algunos tipos ex√≥ticos pueden no parsearse bien
- **Gr√°ficos:** Limitado a tipos b√°sicos de matplotlib

---

## Posibles mejoras futuras

- [ ] Soporte para m√∫ltiples CSVs simult√°neos
- [ ] Joins entre tablas
- [ ] Cach√© de queries frecuentes
- [ ] Modo offline con Ollama (Llama 3.1 8B local)
- [ ] Exportar an√°lisis como notebook Jupyter
- [ ] Integraci√≥n con bases de datos SQL

---

## Licencia

MIT

---

## Autor

David Gonz√°lez

---

## Changelog

### v0.1.0 (en desarrollo)
- Setup inicial
- Carga de CSV con detecci√≥n autom√°tica
- Integraci√≥n con Claude API
- Ejecuci√≥n segura de c√≥digo
- Interfaz Streamlit b√°sica